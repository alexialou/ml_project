{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import collections as co\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"1996_normed.csv\")\n",
    "df = df[df.clerk_school != '9999']\n",
    "y = df['clerk_school']\n",
    "X = df.drop(['clerk_school'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>judge</th>\n",
       "      <th>a</th>\n",
       "      <th>aboard</th>\n",
       "      <th>about</th>\n",
       "      <th>absent</th>\n",
       "      <th>across</th>\n",
       "      <th>after</th>\n",
       "      <th>against</th>\n",
       "      <th>ahead</th>\n",
       "      <th>...</th>\n",
       "      <th>whose</th>\n",
       "      <th>will</th>\n",
       "      <th>with</th>\n",
       "      <th>within</th>\n",
       "      <th>without</th>\n",
       "      <th>would</th>\n",
       "      <th>yet</th>\n",
       "      <th>you</th>\n",
       "      <th>your</th>\n",
       "      <th>yourself</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1995</td>\n",
       "      <td>Arnold_Richard_S</td>\n",
       "      <td>0.019964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1995</td>\n",
       "      <td>Arnold_Richard_S</td>\n",
       "      <td>0.019964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1995</td>\n",
       "      <td>Arnold_Richard_S</td>\n",
       "      <td>0.019964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1995</td>\n",
       "      <td>Arnold_Richard_S</td>\n",
       "      <td>0.019964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.007937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1995</td>\n",
       "      <td>Winter_Ralph_K</td>\n",
       "      <td>0.074410</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.019231</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 189 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   year             judge         a  aboard  about  absent  across  after  \\\n",
       "0  1995  Arnold_Richard_S  0.019964     0.0    0.0     0.0     0.0    0.0   \n",
       "1  1995  Arnold_Richard_S  0.019964     0.0    0.0     0.0     0.0    0.0   \n",
       "2  1995  Arnold_Richard_S  0.019964     0.0    0.0     0.0     0.0    0.0   \n",
       "3  1995  Arnold_Richard_S  0.019964     0.0    0.0     0.0     0.0    0.0   \n",
       "4  1995    Winter_Ralph_K  0.074410     0.0    0.0     0.0     0.0    0.0   \n",
       "\n",
       "    against  ahead    ...     whose      will   with    within  without  \\\n",
       "0  0.095238    0.0    ...     0.125  0.038462  0.032  0.033333     0.04   \n",
       "1  0.095238    0.0    ...     0.125  0.038462  0.032  0.033333     0.04   \n",
       "2  0.095238    0.0    ...     0.125  0.038462  0.032  0.033333     0.04   \n",
       "3  0.095238    0.0    ...     0.125  0.038462  0.032  0.033333     0.04   \n",
       "4  0.000000    0.0    ...     0.000  0.019231  0.032  0.033333     0.00   \n",
       "\n",
       "      would  yet  you  your  yourself  \n",
       "0  0.007937  0.0  0.0   0.0       0.0  \n",
       "1  0.007937  0.0  0.0   0.0       0.0  \n",
       "2  0.007937  0.0  0.0   0.0       0.0  \n",
       "3  0.007937  0.0  0.0   0.0       0.0  \n",
       "4  0.047619  0.0  0.0   0.0       0.0  \n",
       "\n",
       "[5 rows x 189 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                10471\n",
       "unique                 175\n",
       "top       Ripple_Kenneth_F\n",
       "freq                   225\n",
       "Name: judge, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['judge'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    10471.0\n",
       "mean      1995.0\n",
       "std          0.0\n",
       "min       1995.0\n",
       "25%       1995.0\n",
       "50%       1995.0\n",
       "75%       1995.0\n",
       "max       1995.0\n",
       "Name: year, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['year'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def labelCleanUp(label):\n",
    "    label = label.lower()\n",
    "    label = label.replace('nyu', 'new york')\n",
    "    label = label.replace('smu', 'southern methodist')\n",
    "    label = label.replace('case western reserve', 'case western')\n",
    "    pattern1 = 'law|school|college|uc|university|(university of )|(_u)|( u$)|of'\n",
    "    pattern2 = '[-_]'\n",
    "    label = re.sub(pattern1, '', label)\n",
    "    label = re.sub(pattern2, ' ', label)\n",
    "    label = label.lstrip().rstrip()\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#split trainng dataset and test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##get the judge name and year from trainning dataset\n",
    "judgeYearList_train = pd.concat([X_train['judge'],X_train['year']],axis =1)\n",
    "judgeYearList_train = judgeYearList_train.reset_index(drop=True)\n",
    "##get the judge name and year from test dataset\n",
    "judgeYearList_test = pd.concat([X_test['judge'],X_test['year']],axis =1)\n",
    "judgeYearList_test = judgeYearList_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#drop judge from X \n",
    "X_train = X_train.drop(['judge'], axis=1)\n",
    "X_test =  X_test.drop(['judge'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100000000.0, class_weight=None, dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
       "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit model\n",
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(C=1e8)\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predY_train = logreg.predict_proba(X_train)\n",
    "predY_test = logreg.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predDist(y, model):\n",
    "    label = model.classes_\n",
    "    predList = []\n",
    "    for i in range(len(y)):\n",
    "        pred_dist = {}\n",
    "        for j in range(len(label)):\n",
    "            pred_dist.update({label[j]: y[i][j]})\n",
    "        ## sort by value \n",
    "        from operator import itemgetter\n",
    "        sort = sorted(pred_dist.items(), key=itemgetter(1), reverse=True)\n",
    "        predList.append(sort)\n",
    "    return predList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def findLawSch(judgeName, year, dataset):\n",
    "    \n",
    "    sch_list = []\n",
    "    \n",
    "    for i in range(len(dataset['Judge Name'])):\n",
    "            if( dataset['Judge Name'][i] == judgeName and dataset['Year'][i] == year):\n",
    "                sch_list.append(dataset['Clerk Law School'][i])\n",
    "                \n",
    "    cnt = co.Counter(sch_list)\n",
    "    prob_dict = {}\n",
    "    for sch,ct in cnt.items():\n",
    "        prob_dict.update({sch: ct/len(sch_list)})\n",
    "                \n",
    "    return sch_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score(sch_list, pred_list):\n",
    "    correct = 0\n",
    "    unique_sch = list(set(sch_list))\n",
    "    for sch in unique_sch:\n",
    "        for i in range(len(sch_list)):\n",
    "            if sch == pred_list[i][0]:\n",
    "                correct += 1\n",
    "    score = correct / len(sch_list)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aveScore(pred_Y, judge_year_list, model_name,dataset):\n",
    "    total_score = 0\n",
    "    pred_list = predDist(pred_Y, model_name)\n",
    "    for i in range(len(pred_list)):\n",
    "        sch_list = findLawSch(judge_year_list['judge'][i], judge_year_list['year'][i], dataset)\n",
    "        sigle_score = score(sch_list, pred_list[i])\n",
    "        total_score += sigle_score\n",
    "    ave_score = total_score / len(pred_list)\n",
    "    return ave_score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clerk_data = pd.read_excel('ClerksMasterList0811.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score using our metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3156479477057603"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ave_score = aveScore(predY_train, judgeYearList_train, logreg, clerk_data )\n",
    "train_ave_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29619302266361275"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ave_score = aveScore(predY_test, judgeYearList_test, logreg, clerk_data )\n",
    "test_ave_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit\n",
    "## score using built-in metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2242455112695785"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15508021390374332"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf = SVC(probability= True)\n",
    "clf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "## score using built-in metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12670317076276583"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1371275783040489"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_predY_train = clf.predict_proba(X_train)\n",
    "svm_predY_test = clf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score using our metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29283925463729144"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_train_ave_score = aveScore(svm_predY_train, judgeYearList_train, clf, clerk_data )\n",
    "svm_train_ave_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2846638655462205"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_test_ave_score = aveScore(svm_predY_test, judgeYearList_test, clf, clerk_data )\n",
    "svm_test_ave_score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', alpha=1e-05, batch_size='auto',\n",
       "       beta_1=0.9, beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(5, 2), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=1, shuffle=True,\n",
       "       solver='sgd', tol=0.0001, validation_fraction=0.1, verbose=False,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "nnet = MLPClassifier(activation='logistic', solver='sgd', alpha=1e-5,hidden_layer_sizes=(5, 2), random_state=1, max_iter=500)\n",
    "nnet.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nnet_predY_train = nnet.predict_proba(X_train)\n",
    "nnet_predY_test = nnet.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12670317076276583"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1371275783040489"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2204889851012291"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet_train_ave_score = aveScore(nnet_predY_train, judgeYearList_train, nnet, clerk_data )\n",
    "nnet_train_ave_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22469442322383476"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnet_test_ave_score = aveScore(nnet_predY_test, judgeYearList_test, nnet, clerk_data )\n",
    "nnet_test_ave_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10, max_depth=None,min_samples_split=2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lingyuan/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13280779050535504"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rf, X_train, y_train)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf_predY_train = rf.predict_proba(X_train)\n",
    "rf_predY_test = rf.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## score using our metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6911562460206353"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_train_ave_score = aveScore(rf_predY_train, judgeYearList_train, rf, clerk_data )\n",
    "rf_train_ave_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4701935319582382"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_test_ave_score = aveScore(rf_predY_test, judgeYearList_test, rf, clerk_data )\n",
    "rf_test_ave_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF\n",
    "# score using built-in metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lingyuan/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.13280779050535504"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rf, X_train, y_train)\n",
    "scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lingyuan/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1254515579534374"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = cross_val_score(rf, X_test, y_test)\n",
    "scores.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
